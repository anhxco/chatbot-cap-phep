import streamlit as st
from dotenv import load_dotenv
import os
from langchain.vectorstores import FAISS
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.chains import RetrievalQA
from langchain.chat_models import ChatOpenAI

load_dotenv()

st.title("ü§ñ Chatbot h·ªó tr·ª£ c·∫•p ph√©p")

user_question = st.text_input("B·∫°n c·∫ßn h·ªèi g√¨?")

if user_question:
    try:
        db = FAISS.load_local("vectorstore", OpenAIEmbeddings())
        qa = RetrievalQA.from_chain_type(
            llm=ChatOpenAI(model_name="gpt-3.5-turbo"),
            retriever=db.as_retriever()
        )
        response = qa.run(user_question)
        st.write("üìÑ Tr·∫£ l·ªùi:")
        st.write(response)
    except Exception as e:
        st.error(f"L·ªói: {e}")
